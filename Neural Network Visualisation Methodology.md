##Visualisation of Neural Network methodology

**Step - 0** : Read Input and Output

| **X** |      |      |      | Wh   |      |      | Bh   |      |      | hidden_layer_input |      |      | hidden_layer_activation |      |      | Wout | Bout | Output | Y    | E    |
| :---: | :--: | :--: | :--: | ---- | :--: | :--: | ---- | ---- | ---- | ------------------ | ---- | ---- | ----------------------- | ---- | ---- | ---- | ---- | ------ | ---- | ---- |
|   1   |  1   |  0   |  0   |      |      |      |      |      |      |                    |      |      |                         |      |      |      |      |        | 1    |      |
|   1   |  1   |  0   |  1   |      |      |      |      |      |      |                    |      |      |                         |      |      |      |      |        | 1    |      |
|   1   |  0   |  0   |  1   |      |      |      |      |      |      |                    |      |      |                         |      |      |      |      |        | 0    |      |
|       |      |      |      |      |      |      |      |      |      |                    |      |      |                         |      |      |      |      |        |      |      |



**Step -1 ** : Initialize weights and biases with random values.

| **X** |      |      |      | Wh   |      |      | Bh   |      |      | hidden_layer_input |      |      | hidden_layer_activation |      |      | Wout | Bout | Output | Y    | E    |
| ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ----------------------- | ---- | ---- | :--: | ---- | ------ | ---- | ---- |
| 1     | 1    | 0    | 0    | 0.33 | 0.45 | 0.70 | 0.37 | 0.66 | 0.45 |                    |      |      |                         |      |      | 0.33 | 0.65 |        | 1    |      |
| 1     | 1    | 0    | 1    | 0.15 | 0.66 | 0.37 |      |      |      |                    |      |      |                         |      |      | 0.28 |      |        | 1    |      |
| 1     | 0    | 0    | 1    | 0.26 | 0.07 | 0.86 |      |      |      |                    |      |      |                         |      |      | 0.23 |      |        | 0    |      |
|       |      |      |      | 0.56 | 0.98 | 0.63 |      |      |      |                    |      |      |                         |      |      |      |      |        |      |      |



**Step - 2** : Calculate Hidden Layer Input

> *hidden_layer_input= matrix_dot_product(X,wh) + bh*

| **X** |      |      |      | Wh   |      |      | Bh   |      |      | hidden_layer_input |      |      | hidden_layer_activation |      |      | Wout | Bout | Output | Y    | E    |
| ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ----------------------- | ---- | ---- | ---- | ---- | ------ | ---- | ---- |
| 1     | 1    | 0    | 0    | 0.33 | 0.45 | 0.70 | 0.37 | 0.66 | 0.45 | 0.85               | 1.77 | 1.52 |                         |      |      | 0.33 | 0.65 |        | 1    |      |
| 1     | 1    | 0    | 1    | 0.15 | 0.66 | 0.37 |      |      |      | 1.04               | 2.09 | 1.70 |                         |      |      | 0.28 |      |        | 1    |      |
| 1     | 0    | 0    | 1    | 0.26 | 0.07 | 0.86 |      |      |      | 0.89               | 1.43 | 1.33 |                         |      |      | 0.23 |      |        | 0    |      |
|       |      |      |      | 0.56 | 0.98 | 0.63 |      |      |      |                    |      |      |                         |      |      |      |      |        |      |      |

**Step - 3** : Perform non-linear transformation on hidden linear input

> *hiddenlayer_activations = sigmoid(hidden_layer_input)*

| **X** |      |      |      | Wh   |      |      | Bh   |      |      | hidden_layer_input |      |      | hidden_layer_activation |      |      | Wout | Bout | Output | Y    | E    |
| ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ----------------------- | ---- | ---- | ---- | ---- | ------ | ---- | ---- |
| 1     | 1    | 0    | 0    | 0.33 | 0.45 | 0.70 | 0.37 | 0.66 | 0.45 | 0.85               | 1.77 | 1.52 | 0.70                    | 0.85 | 0.82 | 0.33 | 0.65 |        | 1    |      |
| 1     | 1    | 0    | 1    | 0.15 | 0.66 | 0.37 |      |      |      | 1.04               | 2.09 | 1.70 | 0.73                    | 0.88 | 0.84 | 0.28 |      |        | 1    |      |
| 1     | 0    | 0    | 1    | 0.26 | 0.07 | 0.86 |      |      |      | 0.89               | 1.43 | 1.33 | 0.71                    | 0.81 | 0.79 | 0.23 |      |        | 0    |      |
|       |      |      |      | 0.56 | 0.98 | 0.63 |      |      |      |                    |      |      |                         |      |      |      |      |        |      |      |



**Step 4:** Perform linear and non-linear transformation of hidden layer activation at output layer

> *output_layer_input = matrix_dot_product (hiddenlayer_activations \* wout ) + bout*
>
> *output = sigmoid(output_layer_input)*

| **X** |      |      |      | Wh   |      |      | Bh   |      |      | hidden_layer_input |      |      | hidden_layer_activation |      |      | Wout | Bout | Output | Y    | E    |
| ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ----------------------- | ---- | ---- | ---- | ---- | ------ | ---- | ---- |
| 1     | 1    | 0    | 0    | 0.33 | 0.45 | 0.70 | 0.37 | 0.66 | 0.45 | 0.85               | 1.77 | 1.52 | 0.70                    | 0.85 | 0.82 | 0.33 | 0.65 | 0.78   | 1    |      |
| 1     | 1    | 0    | 1    | 0.15 | 0.66 | 0.37 |      |      |      | 1.04               | 2.09 | 1.70 | 0.73                    | 0.88 | 0.84 | 0.28 |      | 0.79   | 1    |      |
| 1     | 0    | 0    | 1    | 0.26 | 0.07 | 0.86 |      |      |      | 0.89               | 1.43 | 1.33 | 0.71                    | 0.81 | 0.79 | 0.23 |      | 0.78   | 0    |      |
|       |      |      |      | 0.56 | 0.98 | 0.63 |      |      |      |                    |      |      |                         |      |      |      |      |        |      |      |



**Step 5:** Calculate gradient of Error(E) at output layer

> *E = y-output*

| **X** |      |      |      | Wh   |      |      | Bh   |      |      | hidden_layer_input |      |      | hidden_layer_activation |      |      | Wout | Bout | Output |  Y   |   E   |
| ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ----------------------- | ---- | ---- | ---- | ---- | ------ | :--: | :---: |
| 1     | 1    | 0    | 0    | 0.33 | 0.45 | 0.70 | 0.37 | 0.66 | 0.45 | 0.85               | 1.77 | 1.52 | 0.70                    | 0.85 | 0.82 | 0.33 | 0.65 | 0.78   |  1   | 0.22  |
| 1     | 1    | 0    | 1    | 0.15 | 0.66 | 0.37 |      |      |      | 1.04               | 2.09 | 1.70 | 0.73                    | 0.88 | 0.84 | 0.28 |      | 0.79   |  1   | 0.21  |
| 1     | 0    | 0    | 1    | 0.26 | 0.07 | 0.86 |      |      |      | 0.89               | 1.43 | 1.33 | 0.71                    | 0.81 | 0.79 | 0.23 |      | 0.78   |  0   | -0.78 |
|       |      |      |      | 0.56 | 0.98 | 0.63 |      |      |      |                    |      |      |                         |      |      |      |      |        |      |       |



**Step 6:** Compute slope at output and hidden layer

> *Slope_output_layer= derivatives_sigmoid(output)*
> *Slope_hidden_layer = derivatives_sigmoid(hiddenlayer_act*ivations)

| **X** |      |      |      | Wh   |      |      | Bh   |      |      | hidden_layer_input |      |      | hidden_layer_activation |      |      | Wout | Bout | Output | Y    | E     |
| ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ----------------------- | ---- | ---- | ---- | ---- | ------ | ---- | ----- |
| 1     | 1    | 0    | 0    | 0.33 | 0.45 | 0.70 | 0.37 | 0.66 | 0.45 | 0.85               | 1.77 | 1.52 | 0.70                    | 0.85 | 0.82 | 0.33 | 0.65 | 0.78   | 1    | 0.22  |
| 1     | 1    | 0    | 1    | 0.15 | 0.66 | 0.37 |      |      |      | 1.04               | 2.09 | 1.70 | 0.73                    | 0.88 | 0.84 | 0.28 |      | 0.79   | 1    | 0.21  |
| 1     | 0    | 0    | 1    | 0.26 | 0.07 | 0.86 |      |      |      | 0.89               | 1.43 | 1.33 | 0.71                    | 0.81 | 0.79 | 0.23 |      | 0.78   | 0    | -0.78 |
|       |      |      |      | 0.56 | 0.98 | 0.63 |      |      |      |                    |      |      |                         |      |      |      |      |        |      |       |

| Slope_hidden_layer |      |      | Slope_output_layer |
| ------------------ | ---- | ---- | :----------------: |
| 0.22               | 0.20 | 0.21 |       0.215        |
| 0.21               | 0.21 | 0.21 |       0.214        |
| 0.22               | 0.21 | 0.21 |       0.215        |



**Step 7:** Compute delta at output layer

>  *d_output = E \* slope_output_layer*

| **X** |      |      |      | Wh   |      |      | Bh   |      |      | hidden_layer_input |      |      | hidden_layer_activation |      |      | Wout | Bout | Output | Y    | E     |
| ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ----------------------- | ---- | ---- | ---- | ---- | ------ | ---- | ----- |
| 1     | 1    | 0    | 0    | 0.33 | 0.45 | 0.70 | 0.37 | 0.66 | 0.45 | 0.85               | 1.77 | 1.52 | 0.70                    | 0.85 | 0.82 | 0.33 | 0.65 | 0.78   | 1    | 0.22  |
| 1     | 1    | 0    | 1    | 0.15 | 0.66 | 0.37 |      |      |      | 1.04               | 2.09 | 1.70 | 0.73                    | 0.88 | 0.84 | 0.28 |      | 0.79   | 1    | 0.21  |
| 1     | 0    | 0    | 1    | 0.26 | 0.07 | 0.86 |      |      |      | 0.89               | 1.43 | 1.33 | 0.71                    | 0.81 | 0.79 | 0.23 |      | 0.78   | 0    | -0.78 |
|       |      |      |      | 0.56 | 0.98 | 0.63 |      |      |      |                    |      |      |                         |      |      |      |      |        |      |       |

| Slope_hidden_layer |      |      | Slope_output_layer | d_output |
| ------------------ | ---- | ---- | ------------------ | -------- |
| 0.22               | 0.20 | 0.21 | 0.215              | 0.047    |
| 0.21               | 0.21 | 0.21 | 0.214              | 0.045    |
| 0.22               | 0.21 | 0.21 | 0.215              | -0.168   |



**Step 8:** Calculate Error at hidden layer

> *Error_at_hidden_layer = matrix_dot_product(d_output, wout.Transpose)*

| **X** |      |      |      | Wh   |      |      | Bh   |      |      | hidden_layer_input |      |      | hidden_layer_activation |      |      | Wout | Bout | Output | Y    | E     |
| ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ----------------------- | ---- | ---- | ---- | ---- | ------ | ---- | ----- |
| 1     | 1    | 0    | 0    | 0.33 | 0.45 | 0.70 | 0.37 | 0.66 | 0.45 | 0.85               | 1.77 | 1.52 | 0.70                    | 0.85 | 0.82 | 0.33 | 0.65 | 0.78   | 1    | 0.22  |
| 1     | 1    | 0    | 1    | 0.15 | 0.66 | 0.37 |      |      |      | 1.04               | 2.09 | 1.70 | 0.73                    | 0.88 | 0.84 | 0.28 |      | 0.79   | 1    | 0.21  |
| 1     | 0    | 0    | 1    | 0.26 | 0.07 | 0.86 |      |      |      | 0.89               | 1.43 | 1.33 | 0.71                    | 0.81 | 0.79 | 0.23 |      | 0.78   | 0    | -0.78 |
|       |      |      |      | 0.56 | 0.98 | 0.63 |      |      |      |                    |      |      |                         |      |      |      |      |        |      |       |

| Slope_hidden_layer |      |      | Slope_output_layer | d_output | Error_at_hidden_layer |       |       |
| ------------------ | ---- | ---- | ------------------ | -------- | --------------------- | ----- | ----- |
| 0.22               | 0.20 | 0.21 | 0.215              | 0.047    | 0.015                 | 0.013 | 0.010 |
| 0.21               | 0.21 | 0.21 | 0.214              | 0.045    | 0.014                 | 0.012 | 0.010 |
| 0.22               | 0.21 | 0.21 | 0.215              | -0.168   | -0.055                | 0.047 | 0.038 |



**Step 9:** Compute delta at hidden layer

>  *d_hiddenlayer = Error_at_hidden_layer \* slope_hidden_layer*

| **X** |      |      |      | Wh   |      |      | Bh   |      |      | hidden_layer_input |      |      | hidden_layer_activation |      |      | Wout | Bout | Output | Y    | E     |
| ----- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------ | ---- | ---- | ----------------------- | ---- | ---- | ---- | ---- | ------ | ---- | ----- |
| 1     | 1    | 0    | 0    | 0.33 | 0.45 | 0.70 | 0.37 | 0.66 | 0.45 | 0.85               | 1.77 | 1.52 | 0.70                    | 0.85 | 0.82 | 0.33 | 0.65 | 0.78   | 1    | 0.22  |
| 1     | 1    | 0    | 1    | 0.15 | 0.66 | 0.37 |      |      |      | 1.04               | 2.09 | 1.70 | 0.73                    | 0.88 | 0.84 | 0.28 |      | 0.79   | 1    | 0.21  |
| 1     | 0    | 0    | 1    | 0.26 | 0.07 | 0.86 |      |      |      | 0.89               | 1.43 | 1.33 | 0.71                    | 0.81 | 0.79 | 0.23 |      | 0.78   | 0    | -0.78 |
|       |      |      |      | 0.56 | 0.98 | 0.63 |      |      |      |                    |      |      |                         |      |      |      |      |        |      |       |

| Slope_hidden_layer |      |      | Slope_output_layer | d_output | Error_at_hidden_layer |       |       | d_hiddenlayer |         |         |
| ------------------ | ---- | ---- | ------------------ | -------- | --------------------- | ----- | ----- | ------------- | ------- | ------- |
| 0.22               | 0.20 | 0.21 | 0.215              | 0.047    | 0.015                 | 0.013 | 0.010 | 0.0085        | 0.0081  | 0.0082  |
| 0.21               | 0.21 | 0.21 | 0.214              | 0.045    | 0.014                 | 0.012 | 0.010 | 0.0082        | 0.0078  | 0.0079  |
| 0.22               | 0.21 | 0.21 | 0.215              | -0.168   | -0.055                | 0.047 | 0.038 | -0.0305       | -0.0291 | -0.0296 |



**Step 10:** Update weight at both output and hidden layer

> *wout = wout + matrix_dot_product(hiddenlayer_activations.Transpose, d_output)\*learning_rate*
> *wh =  wh+ matrix_dot_product(X.Transpose,d_hiddenlayer)\*learning_rate*

| **X** |      |      |      | Wh    |       |       | Bh   |      |      | hidden_layer_input |      |      | hidden_layer_activation |      |      | Wout | Bout | Output | Y    | E     |
| ----- | ---- | ---- | ---- | ----- | ----- | ----- | ---- | ---- | ---- | ------------------ | ---- | ---- | ----------------------- | ---- | ---- | ---- | ---- | ------ | ---- | ----- |
| 1     | 1    | 0    | 0    | 0.328 | 0.448 | 0.698 | 0.37 | 0.66 | 0.45 | 0.85               | 1.77 | 1.52 | 0.70                    | 0.85 | 0.82 | 0.27 | 0.65 | 0.78   | 1    | 0.22  |
| 1     | 1    | 0    | 1    | 0.151 | 0.661 | 0.371 |      |      |      | 1.04               | 2.09 | 1.70 | 0.73                    | 0.88 | 0.84 | 0.27 |      | 0.79   | 1    | 0.21  |
| 1     | 0    | 0    | 1    | 0.26  | 0.07  | 0.86  |      |      |      | 0.89               | 1.43 | 1.33 | 0.71                    | 0.81 | 0.79 | 0.22 |      | 0.78   | 0    | -0.78 |
|       |      |      |      | 0.555 | 0.977 | 0.627 |      |      |      |                    |      |      |                         |      |      |      |      |        |      |       |

| Slope_hidden_layer |      |      | Slope_output_layer | d_output | Error_at_hidden_layer |       |       | d_hiddenlayer |         |         |
| ------------------ | ---- | ---- | ------------------ | -------- | --------------------- | ----- | ----- | ------------- | ------- | ------- |
| 0.22               | 0.20 | 0.21 | 0.215              | 0.047    | 0.015                 | 0.013 | 0.010 | 0.0085        | 0.0081  | 0.0082  |
| 0.21               | 0.21 | 0.21 | 0.214              | 0.045    | 0.014                 | 0.012 | 0.010 | 0.0082        | 0.0078  | 0.0079  |
| 0.22               | 0.21 | 0.21 | 0.215              | -0.168   | -0.055                | 0.047 | 0.038 | -0.0305       | -0.0291 | -0.0296 |



**Step 11:** Update biases at both output and hidden layer

> *bh = bh + sum(d_hiddenlayer, axis=0) \* learning_rate*
>
> *bout = bout + sum(d_output, axis=0)\*learning_rate*

| **X** |      |      |      | Wh    |       |       | Bh    |       |       | hidden_layer_input |      |      | hidden_layer_activation |      |      | Wout | Bout  | Output | Y    | E     |
| ----- | ---- | ---- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ------------------ | ---- | ---- | ----------------------- | ---- | ---- | ---- | ----- | ------ | ---- | ----- |
| 1     | 1    | 0    | 0    | 0.328 | 0.448 | 0.698 | 0.372 | 0.662 | 0.441 | 0.85               | 1.77 | 1.52 | 0.70                    | 0.85 | 0.82 | 0.27 | 0.642 | 0.78   | 1    | 0.22  |
| 1     | 1    | 0    | 1    | 0.151 | 0.661 | 0.371 |       |       |       | 1.04               | 2.09 | 1.70 | 0.73                    | 0.88 | 0.84 | 0.27 |       | 0.79   | 1    | 0.21  |
| 1     | 0    | 0    | 1    | 0.26  | 0.07  | 0.86  |       |       |       | 0.89               | 1.43 | 1.33 | 0.71                    | 0.81 | 0.79 | 0.22 |       | 0.78   | 0    | -0.78 |
|       |      |      |      | 0.555 | 0.977 | 0.627 |       |       |       |                    |      |      |                         |      |      |      |       |        |      |       |

| Slope_hidden_layer |      |      | Slope_output_layer | d_output | Error_at_hidden_layer |       |       | d_hiddenlayer |         |         |
| ------------------ | ---- | ---- | ------------------ | -------- | --------------------- | ----- | ----- | ------------- | ------- | ------- |
| 0.22               | 0.20 | 0.21 | 0.215              | 0.047    | 0.015                 | 0.013 | 0.010 | 0.0085        | 0.0081  | 0.0082  |
| 0.21               | 0.21 | 0.21 | 0.214              | 0.045    | 0.014                 | 0.012 | 0.010 | 0.0082        | 0.0078  | 0.0079  |
| 0.22               | 0.21 | 0.21 | 0.215              | -0.168   | -0.055                | 0.047 | 0.038 | -0.0305       | -0.0291 | -0.0296 |



## Sources

* https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/

